{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "192b9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import nibabel as nb\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "core_functions_path = os.path.abspath('../core_functions')\n",
    "sys.path.append(core_functions_path)\n",
    "\n",
    "\n",
    "from compute_eigenvectors_sliding_cov import compute_eigs_cov\n",
    "from dysco_distance import dysco_distance\n",
    "from dysco_mode_alignment import dysco_mode_alignment\n",
    "from dysco_norm import dysco_norm\n",
    "from fMRI_Processing.surf_cifti_data import surf_data_from_cifti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c30a0",
   "metadata": {},
   "source": [
    "# Simple DySCO Tutorial \n",
    "\n",
    "### If you want to learn how to use dysco this is the right place! This script teaches you how to run the core functions to build your dysco analysis pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ced5fb",
   "metadata": {},
   "source": [
    "## Step 1: Load the timeseries. \n",
    "### This should be a matrix, each row is a timepoint, each column is a signal/brain area/feature. So it's TxN. \n",
    "\n",
    "### This might be the most ~annoying~ crucial part, the data preprocessing/format. Here we will use .nii format and use nibabel to load. But there are many other ways to do this. \n",
    "\n",
    "#### N.B. IF you have a suitable .nii file input the full path into the 'file_path', ALTERNATIVELY, we have done this step on an existing .nii file from the HCP project and saved it as an .npy file. If you wish to use this, skip the next cell and load the .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "019fcaf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '*.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '*.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.nii\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load NIfTI file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m cifti \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mload(file_path)\n\u001b[1;32m      6\u001b[0m cifti_data \u001b[38;5;241m=\u001b[39m cifti\u001b[38;5;241m.\u001b[39mget_fdata(dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m cifti_hdr \u001b[38;5;241m=\u001b[39m cifti\u001b[38;5;241m.\u001b[39mheader\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nibabel/loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '*.nii'"
     ]
    }
   ],
   "source": [
    "# SKIP THIS CELL (Unless you have a .nii file)\n",
    "file_path = '*.nii'\n",
    "\n",
    "# Load NIfTI file\n",
    "cifti = nb.load(file_path)\n",
    "cifti_data = cifti.get_fdata(dtype=np.float32)\n",
    "cifti_hdr = cifti.header\n",
    "nifti_hdr = cifti.nifti_header\n",
    "\n",
    "axes = [cifti_hdr.get_axis(i) for i in range(cifti.ndim)]\n",
    "\n",
    "# Only using half the brain here \n",
    "left_brain = surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_LEFT')\n",
    "# right_brain = surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_RIGHT')\n",
    "\n",
    "brain_load = left_brain\n",
    "\n",
    "# Can filter here (based on tissue boundaries etc)\n",
    "brain_load = brain_load.T\n",
    "zero_columns = np.all(brain_load == 0, axis=0)\n",
    "filtered_array = brain_load[:, ~zero_columns]\n",
    "brain = filtered_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf9f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN this cell to load the saved .npy file\n",
    "brain = np.load('Test_Brain/Test_Brain_1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec46696",
   "metadata": {},
   "source": [
    "## Step 2: Run the recurrence matrix EVD\n",
    "\n",
    "### After you have selected the type of matrix (see paper) and preprocessed the data, run the recurrence matrix EVD for the specified matrix. For example, here we are running it for a sliding window correlation matrix with a window of 21 (odd numbers for symmetry). Remember that the rank (=n of non-null eigenvalues) is lower than window size (see paper). In this case, we calculate the first 10 eigenvectors as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caf3726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating eigenvectors and eigenvalues:: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 385/385 [00:15<00:00, 24.56it/s]\n"
     ]
    }
   ],
   "source": [
    "half_window_size = 10\n",
    "n_eigen = 10\n",
    "\n",
    "eigenvectors, eigenvalues = compute_eigs_cov(brain, n_eigen, half_window_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331463d4",
   "metadata": {},
   "source": [
    "### Now you have eigenvectors and eigenvalues. eigenvalues is a 2D matrix, where each column corresponds to our 10 eigenvalues at each time point. eigenvectors is 3D, because it is a matrix of eigenvectors for each time point. Every column of the matrix is an eigenvector, and indeed every matrix has 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d08ea8",
   "metadata": {},
   "source": [
    "## Step 3: Compute DySCo measures:\n",
    "\n",
    "### Now that we have this EVD representation of our sliding-window correlation matrix, we can compute the DySCo measures.\n",
    "\n",
    "#### These are: \n",
    "1. NORM \n",
    "2. DISTANCE \n",
    "3. Reconfiguration Speed \n",
    "4. Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6b59d",
   "metadata": {},
   "source": [
    "## Norm\n",
    "\n",
    "### This is the time-varying norm, computed from eigenvalues (see paper), so at each time point you have the norm of the matrix. Let us compute the norm 2, but there are different norms available (see paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8764a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm2 = dysco_norm(eigenvalues, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acfd73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1. From norm we can compute a derived measure, which is spectral\n",
    "# metastability - see paper.\n",
    "metastability = np.std(norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b514a2",
   "metadata": {},
   "source": [
    "## Distance\n",
    "\n",
    "### We can compute the distance between dynamic matrices at 2 different time points. For example, let us use the distance 2 to compute the Functional Connectivity Dynamics (FCD) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcf9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = eigenvectors.shape[0]\n",
    "fcd = np.zeros((T, T))\n",
    "\n",
    "for i in range(T):\n",
    "    for j in range(i + 1, T):\n",
    "        fcd[i, j] = dysco_distance(eigenvectors[i, :, :], eigenvectors[j, :, :], 2)\n",
    "        fcd[j, i] = fcd[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be9f1d",
   "metadata": {},
   "source": [
    "## Reconfiguration speed\n",
    "\n",
    "### is just the distance between the matrix at time t and the matrix at time t-lag, so if we already have the FCD matrix, the reconfiguration speed will be just derived from that: (here we suppose lag = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed966f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 20\n",
    "speed = np.zeros(T - lag)\n",
    "for i in range(T - lag):\n",
    "    speed[i] = fcd[i, i + lag]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8ab08",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "### For Von Neumann Entropy, you just need the eigenvalues (like for the norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10006ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "                      \n",
    "entropy = eigenvalues / np.tile(np.sum(eigenvalues, axis=0), (n_eigen, 1))\n",
    "entropy = -np.sum(np.log(entropy) * entropy, axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
